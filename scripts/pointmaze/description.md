The data is collected from the [`{env_id}`](https://robotics.farama.org/envs/maze/point_maze/) environment, which contains a U shape maze. The agent uses a PD controller to follow a path of waypoints generated with QIteration until it reaches the goal. The task is continuing which means that when the agent reaches the goal the environment generates a new random goal without resetting the location of the agent. The reward function is dense, being the exponential negative Euclidean distance between the goal and the agent. To add variance to the collected paths random noise is added to the actions taken by the agent.